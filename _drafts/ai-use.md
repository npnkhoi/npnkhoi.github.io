- how should young professional think about AI?
- what are they actually thinking? procs and cons?
- any critique?


Uses:
- to speed up things
- to get real-life recommendations:
- to self-teach: anything
- to fix one's self: tarot, fortune telling, therapy, philosophical inquiries


Cases to think about:
- CS PhD students talk about using ChatGPT to do a 2-minute quiz.
- CS MS students code the entire homework assignment using Claude. No actual
  coding involve.
+ A HuggingFace engineer uses the same approach to build a product that is useful
  for the entire community?
+ A CS professor who no longer codes. He loses interests in coding entirely. He
  outsources all programming/technical tasks to his assistants. Now potentially
LMs.

Analogy: Going from A to B. Alice took the bus the entire way, cost 10 minutes,
and have some time to do her own stuff. Bob run the whole way, cost 30 minutes,
not done anything else but just run.

It depends on the context. If it was a marathon, Alice was cheating (bad),
while Bob is the real one. Otherwise, if it was to get to a class starting in
15 minutes, Alice is the smart one while Bob is questionable.

I am at no position to judge the use cases above. But for oneself, they must
now be even clearer about their goals, and decide whether or not to use
technological assistance based on that.

Previously, like it or not, everyone has to go through the same labor.
Learnings may be the side effects, which they appreciate later. Now, there is
a choice to do it faster and outsources thinking. How much would we "learn to
use the tool", and how much should we still touch the sea bed with our bare
hands?
